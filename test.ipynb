{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28386 images belonging to 8 classes.\n",
      "Found 7099 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_dir=\"fer2013plus/fer2013/train/\"\n",
    "test_dir=\"fer2013plus/fer2013/test/\"\n",
    "\n",
    "\n",
    "train_data = train_datagen.flow_from_directory(train_dir,\n",
    "                                               batch_size=128,\n",
    "                                               target_size=(48,48),\n",
    "                                               class_mode=\"categorical\",\n",
    "                                               seed=42)\n",
    "test_data = test_datagen.flow_from_directory(test_dir,\n",
    "                                             batch_size=128,\n",
    "                                             target_size=(48,48),\n",
    "                                             class_mode=\"categorical\",\n",
    "                                             seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Callback functions\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',    \n",
    "    min_delta=0.0001,      \n",
    "    patience=4,            \n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_accuracy',  #val_loss no overfitting   \n",
    "    min_delta=0.0001,  \n",
    "    mode=\"min\",\n",
    "    factor=0.5,                 \n",
    "    patience=4,                 \n",
    "    min_lr=1e-7,                \n",
    "    verbose=1                   \n",
    ")\n",
    "\n",
    "# checkpoint = tf.keras.callbacks.ModelCheckpoint(\"model.h5\", monitor='val_accuracy', \n",
    "#                          verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "222/222 [==============================] - 12s 50ms/step - loss: 1.4790 - accuracy: 0.4336 - val_loss: 1.4027 - val_accuracy: 0.4751 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "222/222 [==============================] - 10s 47ms/step - loss: 1.3607 - accuracy: 0.4888 - val_loss: 1.3582 - val_accuracy: 0.4946 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "222/222 [==============================] - 10s 47ms/step - loss: 1.3256 - accuracy: 0.5016 - val_loss: 1.3370 - val_accuracy: 0.5018 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "222/222 [==============================] - 10s 47ms/step - loss: 1.3029 - accuracy: 0.5082 - val_loss: 1.3211 - val_accuracy: 0.5096 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "221/222 [============================>.] - ETA: 0s - loss: 1.2873 - accuracy: 0.5170\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "222/222 [==============================] - 11s 47ms/step - loss: 1.2866 - accuracy: 0.5173 - val_loss: 1.3094 - val_accuracy: 0.5150 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "222/222 [==============================] - 11s 47ms/step - loss: 1.2737 - accuracy: 0.5209 - val_loss: 1.3031 - val_accuracy: 0.5167 - lr: 5.0000e-04\n",
      "Epoch 7/100\n",
      "222/222 [==============================] - 11s 48ms/step - loss: 1.2682 - accuracy: 0.5231 - val_loss: 1.3011 - val_accuracy: 0.5166 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "222/222 [==============================] - 11s 48ms/step - loss: 1.2630 - accuracy: 0.5252 - val_loss: 1.2970 - val_accuracy: 0.5194 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "221/222 [============================>.] - ETA: 0s - loss: 1.2580 - accuracy: 0.5272\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "222/222 [==============================] - 11s 48ms/step - loss: 1.2583 - accuracy: 0.5272 - val_loss: 1.2932 - val_accuracy: 0.5222 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "222/222 [==============================] - 11s 48ms/step - loss: 1.2533 - accuracy: 0.5280 - val_loss: 1.2912 - val_accuracy: 0.5219 - lr: 2.5000e-04\n",
      "Epoch 11/100\n",
      "222/222 [==============================] - 11s 48ms/step - loss: 1.2513 - accuracy: 0.5298 - val_loss: 1.2906 - val_accuracy: 0.5212 - lr: 2.5000e-04\n",
      "Epoch 12/100\n",
      "222/222 [==============================] - 11s 48ms/step - loss: 1.2495 - accuracy: 0.5293 - val_loss: 1.2886 - val_accuracy: 0.5225 - lr: 2.5000e-04\n",
      "Epoch 13/100\n",
      "221/222 [============================>.] - ETA: 0s - loss: 1.2474 - accuracy: 0.5309\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "222/222 [==============================] - 11s 48ms/step - loss: 1.2473 - accuracy: 0.5309 - val_loss: 1.2892 - val_accuracy: 0.5204 - lr: 2.5000e-04\n",
      "Epoch 14/100\n",
      "222/222 [==============================] - 11s 48ms/step - loss: 1.2455 - accuracy: 0.5309 - val_loss: 1.2870 - val_accuracy: 0.5233 - lr: 1.2500e-04\n",
      "Epoch 15/100\n",
      "222/222 [==============================] - 11s 48ms/step - loss: 1.2444 - accuracy: 0.5326 - val_loss: 1.2858 - val_accuracy: 0.5239 - lr: 1.2500e-04\n",
      "Epoch 16/100\n",
      "222/222 [==============================] - 11s 48ms/step - loss: 1.2433 - accuracy: 0.5316 - val_loss: 1.2852 - val_accuracy: 0.5230 - lr: 1.2500e-04\n",
      "Epoch 17/100\n",
      "221/222 [============================>.] - ETA: 0s - loss: 1.2429 - accuracy: 0.5320\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "222/222 [==============================] - 11s 48ms/step - loss: 1.2426 - accuracy: 0.5321 - val_loss: 1.2846 - val_accuracy: 0.5253 - lr: 1.2500e-04\n",
      "Epoch 18/100\n",
      "222/222 [==============================] - 11s 48ms/step - loss: 1.2416 - accuracy: 0.5332 - val_loss: 1.2844 - val_accuracy: 0.5226 - lr: 6.2500e-05\n",
      "Epoch 19/100\n",
      "222/222 [==============================] - 11s 48ms/step - loss: 1.2410 - accuracy: 0.5328 - val_loss: 1.2841 - val_accuracy: 0.5236 - lr: 6.2500e-05\n",
      "Epoch 20/100\n",
      "222/222 [==============================] - 11s 48ms/step - loss: 1.2407 - accuracy: 0.5336 - val_loss: 1.2838 - val_accuracy: 0.5218 - lr: 6.2500e-05\n",
      "Epoch 21/100\n",
      "221/222 [============================>.] - ETA: 0s - loss: 1.2407 - accuracy: 0.5323\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "222/222 [==============================] - 11s 48ms/step - loss: 1.2403 - accuracy: 0.5326 - val_loss: 1.2837 - val_accuracy: 0.5230 - lr: 6.2500e-05\n",
      "Epoch 22/100\n",
      "222/222 [==============================] - 11s 48ms/step - loss: 1.2397 - accuracy: 0.5338 - val_loss: 1.2833 - val_accuracy: 0.5239 - lr: 3.1250e-05\n",
      "Epoch 23/100\n",
      "222/222 [==============================] - 11s 49ms/step - loss: 1.2395 - accuracy: 0.5335 - val_loss: 1.2831 - val_accuracy: 0.5240 - lr: 3.1250e-05\n",
      "Epoch 24/100\n",
      "222/222 [==============================] - 11s 48ms/step - loss: 1.2393 - accuracy: 0.5334 - val_loss: 1.2830 - val_accuracy: 0.5242 - lr: 3.1250e-05\n",
      "Epoch 25/100\n",
      "221/222 [============================>.] - ETA: 0s - loss: 1.2391 - accuracy: 0.5334\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "222/222 [==============================] - 11s 48ms/step - loss: 1.2391 - accuracy: 0.5336 - val_loss: 1.2830 - val_accuracy: 0.5226 - lr: 3.1250e-05\n",
      "Epoch 26/100\n",
      "222/222 [==============================] - 11s 48ms/step - loss: 1.2388 - accuracy: 0.5339 - val_loss: 1.2829 - val_accuracy: 0.5235 - lr: 1.5625e-05\n",
      "Epoch 27/100\n",
      "222/222 [==============================] - 11s 48ms/step - loss: 1.2387 - accuracy: 0.5340 - val_loss: 1.2828 - val_accuracy: 0.5236 - lr: 1.5625e-05\n",
      "Epoch 28/100\n",
      "222/222 [==============================] - 11s 48ms/step - loss: 1.2386 - accuracy: 0.5338 - val_loss: 1.2828 - val_accuracy: 0.5229 - lr: 1.5625e-05\n",
      "Epoch 29/100\n",
      "221/222 [============================>.] - ETA: 0s - loss: 1.2384 - accuracy: 0.5342\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "222/222 [==============================] - 11s 49ms/step - loss: 1.2385 - accuracy: 0.5340 - val_loss: 1.2827 - val_accuracy: 0.5226 - lr: 1.5625e-05\n",
      "Epoch 30/100\n",
      "222/222 [==============================] - 11s 49ms/step - loss: 1.2383 - accuracy: 0.5340 - val_loss: 1.2826 - val_accuracy: 0.5233 - lr: 7.8125e-06\n",
      "Epoch 31/100\n",
      "222/222 [==============================] - 11s 49ms/step - loss: 1.2383 - accuracy: 0.5338 - val_loss: 1.2826 - val_accuracy: 0.5233 - lr: 7.8125e-06\n",
      "Epoch 32/100\n",
      "222/222 [==============================] - 11s 49ms/step - loss: 1.2382 - accuracy: 0.5336 - val_loss: 1.2826 - val_accuracy: 0.5230 - lr: 7.8125e-06\n",
      "Epoch 33/100\n",
      "221/222 [============================>.] - ETA: 0s - loss: 1.2380 - accuracy: 0.5339\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "222/222 [==============================] - 11s 49ms/step - loss: 1.2382 - accuracy: 0.5338 - val_loss: 1.2825 - val_accuracy: 0.5233 - lr: 7.8125e-06\n",
      "Epoch 34/100\n",
      "222/222 [==============================] - 11s 49ms/step - loss: 1.2381 - accuracy: 0.5340 - val_loss: 1.2825 - val_accuracy: 0.5233 - lr: 3.9063e-06\n",
      "Epoch 35/100\n",
      "222/222 [==============================] - 11s 49ms/step - loss: 1.2381 - accuracy: 0.5339 - val_loss: 1.2825 - val_accuracy: 0.5232 - lr: 3.9063e-06\n",
      "Epoch 36/100\n",
      "222/222 [==============================] - 11s 49ms/step - loss: 1.2381 - accuracy: 0.5339 - val_loss: 1.2825 - val_accuracy: 0.5233 - lr: 3.9063e-06\n",
      "Epoch 37/100\n",
      "221/222 [============================>.] - ETA: 0s - loss: 1.2375 - accuracy: 0.5344\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "222/222 [==============================] - 11s 49ms/step - loss: 1.2380 - accuracy: 0.5340 - val_loss: 1.2825 - val_accuracy: 0.5233 - lr: 3.9063e-06\n",
      "Epoch 37: early stopping\n",
      "Epoch 1/100\n",
      "222/222 [==============================] - 14s 60ms/step - loss: 1.5201 - accuracy: 0.4104 - val_loss: 1.4264 - val_accuracy: 0.4572 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "222/222 [==============================] - 13s 59ms/step - loss: 1.3859 - accuracy: 0.4695 - val_loss: 1.3868 - val_accuracy: 0.4803 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "222/222 [==============================] - 13s 59ms/step - loss: 1.3533 - accuracy: 0.4820 - val_loss: 1.3721 - val_accuracy: 0.4760 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "222/222 [==============================] - 13s 59ms/step - loss: 1.3325 - accuracy: 0.4914 - val_loss: 1.3516 - val_accuracy: 0.4898 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "221/222 [============================>.] - ETA: 0s - loss: 1.3178 - accuracy: 0.4942\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "222/222 [==============================] - 13s 59ms/step - loss: 1.3182 - accuracy: 0.4942 - val_loss: 1.3429 - val_accuracy: 0.4947 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "222/222 [==============================] - 13s 59ms/step - loss: 1.3045 - accuracy: 0.5032 - val_loss: 1.3361 - val_accuracy: 0.4975 - lr: 5.0000e-04\n",
      "Epoch 7/100\n",
      "222/222 [==============================] - 13s 59ms/step - loss: 1.2994 - accuracy: 0.5063 - val_loss: 1.3304 - val_accuracy: 0.5005 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "222/222 [==============================] - 13s 59ms/step - loss: 1.2940 - accuracy: 0.5097 - val_loss: 1.3267 - val_accuracy: 0.5032 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "221/222 [============================>.] - ETA: 0s - loss: 1.2904 - accuracy: 0.5091\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "222/222 [==============================] - 13s 59ms/step - loss: 1.2900 - accuracy: 0.5092 - val_loss: 1.3253 - val_accuracy: 0.4994 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "222/222 [==============================] - 13s 59ms/step - loss: 1.2847 - accuracy: 0.5132 - val_loss: 1.3210 - val_accuracy: 0.5051 - lr: 2.5000e-04\n",
      "Epoch 11/100\n",
      "222/222 [==============================] - 13s 59ms/step - loss: 1.2830 - accuracy: 0.5136 - val_loss: 1.3198 - val_accuracy: 0.5089 - lr: 2.5000e-04\n",
      "Epoch 12/100\n",
      "222/222 [==============================] - 13s 59ms/step - loss: 1.2810 - accuracy: 0.5146 - val_loss: 1.3201 - val_accuracy: 0.5037 - lr: 2.5000e-04\n",
      "Epoch 13/100\n",
      "221/222 [============================>.] - ETA: 0s - loss: 1.2793 - accuracy: 0.5154\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "222/222 [==============================] - 13s 59ms/step - loss: 1.2793 - accuracy: 0.5154 - val_loss: 1.3178 - val_accuracy: 0.5066 - lr: 2.5000e-04\n",
      "Epoch 14/100\n",
      "222/222 [==============================] - 13s 59ms/step - loss: 1.2769 - accuracy: 0.5161 - val_loss: 1.3168 - val_accuracy: 0.5075 - lr: 1.2500e-04\n",
      "Epoch 15/100\n",
      "222/222 [==============================] - 13s 59ms/step - loss: 1.2759 - accuracy: 0.5170 - val_loss: 1.3162 - val_accuracy: 0.5080 - lr: 1.2500e-04\n",
      "Epoch 16/100\n",
      "222/222 [==============================] - 13s 59ms/step - loss: 1.2750 - accuracy: 0.5176 - val_loss: 1.3163 - val_accuracy: 0.5054 - lr: 1.2500e-04\n",
      "Epoch 17/100\n",
      "221/222 [============================>.] - ETA: 0s - loss: 1.2745 - accuracy: 0.5174\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "222/222 [==============================] - 13s 59ms/step - loss: 1.2743 - accuracy: 0.5175 - val_loss: 1.3149 - val_accuracy: 0.5077 - lr: 1.2500e-04\n",
      "Epoch 18/100\n",
      "222/222 [==============================] - 13s 59ms/step - loss: 1.2730 - accuracy: 0.5174 - val_loss: 1.3146 - val_accuracy: 0.5085 - lr: 6.2500e-05\n",
      "Epoch 19/100\n",
      "222/222 [==============================] - 13s 59ms/step - loss: 1.2727 - accuracy: 0.5177 - val_loss: 1.3148 - val_accuracy: 0.5080 - lr: 6.2500e-05\n",
      "Epoch 20/100\n",
      "222/222 [==============================] - 13s 59ms/step - loss: 1.2724 - accuracy: 0.5175 - val_loss: 1.3137 - val_accuracy: 0.5080 - lr: 6.2500e-05\n",
      "Epoch 21/100\n",
      "221/222 [============================>.] - ETA: 0s - loss: 1.2724 - accuracy: 0.5171\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "222/222 [==============================] - 13s 59ms/step - loss: 1.2720 - accuracy: 0.5173 - val_loss: 1.3135 - val_accuracy: 0.5078 - lr: 6.2500e-05\n",
      "Epoch 22/100\n",
      "222/222 [==============================] - 13s 59ms/step - loss: 1.2713 - accuracy: 0.5174 - val_loss: 1.3135 - val_accuracy: 0.5078 - lr: 3.1250e-05\n",
      "Epoch 23/100\n",
      "222/222 [==============================] - 13s 59ms/step - loss: 1.2712 - accuracy: 0.5176 - val_loss: 1.3132 - val_accuracy: 0.5091 - lr: 3.1250e-05\n",
      "Epoch 24/100\n",
      "222/222 [==============================] - 13s 59ms/step - loss: 1.2709 - accuracy: 0.5175 - val_loss: 1.3130 - val_accuracy: 0.5089 - lr: 3.1250e-05\n",
      "Epoch 25/100\n",
      "221/222 [============================>.] - ETA: 0s - loss: 1.2706 - accuracy: 0.5183\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "222/222 [==============================] - 13s 59ms/step - loss: 1.2707 - accuracy: 0.5179 - val_loss: 1.3128 - val_accuracy: 0.5099 - lr: 3.1250e-05\n",
      "Epoch 26/100\n",
      "222/222 [==============================] - 13s 59ms/step - loss: 1.2704 - accuracy: 0.5183 - val_loss: 1.3128 - val_accuracy: 0.5096 - lr: 1.5625e-05\n",
      "Epoch 27/100\n",
      "222/222 [==============================] - 13s 59ms/step - loss: 1.2703 - accuracy: 0.5179 - val_loss: 1.3126 - val_accuracy: 0.5095 - lr: 1.5625e-05\n",
      "Epoch 28/100\n",
      "222/222 [==============================] - 13s 59ms/step - loss: 1.2702 - accuracy: 0.5186 - val_loss: 1.3126 - val_accuracy: 0.5095 - lr: 1.5625e-05\n",
      "Epoch 29/100\n",
      "221/222 [============================>.] - ETA: 0s - loss: 1.2701 - accuracy: 0.5182\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "222/222 [==============================] - 13s 59ms/step - loss: 1.2701 - accuracy: 0.5182 - val_loss: 1.3125 - val_accuracy: 0.5094 - lr: 1.5625e-05\n",
      "Epoch 30/100\n",
      "222/222 [==============================] - 13s 59ms/step - loss: 1.2700 - accuracy: 0.5186 - val_loss: 1.3125 - val_accuracy: 0.5091 - lr: 7.8125e-06\n",
      "Epoch 31/100\n",
      "222/222 [==============================] - 13s 59ms/step - loss: 1.2699 - accuracy: 0.5185 - val_loss: 1.3125 - val_accuracy: 0.5095 - lr: 7.8125e-06\n",
      "Epoch 32/100\n",
      "222/222 [==============================] - 13s 59ms/step - loss: 1.2699 - accuracy: 0.5187 - val_loss: 1.3125 - val_accuracy: 0.5096 - lr: 7.8125e-06\n",
      "Epoch 33/100\n",
      "221/222 [============================>.] - ETA: 0s - loss: 1.2699 - accuracy: 0.5183\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "222/222 [==============================] - 13s 59ms/step - loss: 1.2698 - accuracy: 0.5185 - val_loss: 1.3124 - val_accuracy: 0.5094 - lr: 7.8125e-06\n",
      "Epoch 34/100\n",
      "222/222 [==============================] - 13s 59ms/step - loss: 1.2697 - accuracy: 0.5185 - val_loss: 1.3124 - val_accuracy: 0.5094 - lr: 3.9063e-06\n",
      "Epoch 35/100\n",
      "222/222 [==============================] - 13s 59ms/step - loss: 1.2697 - accuracy: 0.5189 - val_loss: 1.3124 - val_accuracy: 0.5098 - lr: 3.9063e-06\n",
      "Epoch 36/100\n",
      "222/222 [==============================] - 13s 59ms/step - loss: 1.2697 - accuracy: 0.5186 - val_loss: 1.3124 - val_accuracy: 0.5096 - lr: 3.9063e-06\n",
      "Epoch 37/100\n",
      "221/222 [============================>.] - ETA: 0s - loss: 1.2697 - accuracy: 0.5184\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "222/222 [==============================] - 13s 59ms/step - loss: 1.2697 - accuracy: 0.5185 - val_loss: 1.3123 - val_accuracy: 0.5096 - lr: 3.9063e-06\n",
      "Epoch 38/100\n",
      "221/222 [============================>.] - ETA: 0s - loss: 1.2696 - accuracy: 0.5189Restoring model weights from the end of the best epoch: 34.\n",
      "222/222 [==============================] - 13s 59ms/step - loss: 1.2696 - accuracy: 0.5187 - val_loss: 1.3123 - val_accuracy: 0.5096 - lr: 1.9531e-06\n",
      "Epoch 38: early stopping\n"
     ]
    }
   ],
   "source": [
    "# VGG 19\n",
    "# 1. Create a base model with tf.keras.applciations\n",
    "base_model1 = tf.keras.applications.VGG16(include_top=False, input_shape=(48,48,3)) # include_top -> last layer (will be different for different datasets)\n",
    "base_model2 = tf.keras.applications.VGG19(include_top=False, input_shape=(48,48,3))\n",
    "# 2. Freeze the base model, underlying pre-trained weights arent updated during training\n",
    "base_model1.trainable=False\n",
    "base_model2.trainable=False\n",
    "\n",
    "# 3. Create inputs into our model\n",
    "inputs = tf.keras.layers.Input(shape=(48,48,3),\n",
    "                               name=\"input_layer\")\n",
    "\n",
    "# 4. (Optional) -> if using resnet -> need to normalize inputs -> not needed for EfficientNet\n",
    "# x = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)(inputs)\n",
    "\n",
    "# 5. Pass the inputs to base_model\n",
    "x1 = base_model1(inputs)\n",
    "x2 = base_model2(inputs)\n",
    "\n",
    "# print(\"shape after passing inputs through base_model: \"+str(x.shape))\n",
    "\n",
    "# 6. Average pool the outputs of the base_model (aggregate all most of information, reduce number of computations)\n",
    "x1 = tf.keras.layers.GlobalAveragePooling2D(name=\"average_global_pooling_layer\")(x1)\n",
    "x2 = tf.keras.layers.GlobalAveragePooling2D(name=\"average_global_pooling_layer\")(x2)\n",
    "\n",
    "# print(\"Shape after GlobalAveragePooling2D: \"+str(x.shape))\n",
    "\n",
    "# 7. Create the output activation layer\n",
    "outputs1 = tf.keras.layers.Dense(8,activation=tf.keras.activations.softmax,name=\"output_layers\")(x1)\n",
    "outputs2 = tf.keras.layers.Dense(8,activation=tf.keras.activations.softmax,name=\"output_layers\")(x2)\n",
    "\n",
    "# 8. Combine input with the outputs into a model\n",
    "model_vgg16 = tf.keras.Model(inputs,outputs1)\n",
    "model_vgg19 = tf.keras.Model(inputs,outputs2)\n",
    "\n",
    "# 9. Compile the model\n",
    "model_vgg16.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# 10. Fit the model\n",
    "history_vgg16 = model_vgg16.fit(train_data,\n",
    "                        epochs=100,\n",
    "                        steps_per_epoch=len(train_data),\n",
    "                        validation_data=test_data,\n",
    "                        validation_steps=len(test_data),\n",
    "                        callbacks=[lr_scheduler,early_stopping])\n",
    "\n",
    "\n",
    "# 9. Compile the model\n",
    "model_vgg19.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# 10. Fit the model\n",
    "history_vgg19 = model_vgg19.fit(train_data,\n",
    "                        epochs=100,\n",
    "                        steps_per_epoch=len(train_data),\n",
    "                        validation_data=test_data,\n",
    "                        validation_steps=len(test_data),\n",
    "                        callbacks=[lr_scheduler,early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "222/222 [==============================] - 11s 39ms/step - loss: 1.6670 - accuracy: 0.4196 - val_loss: 1.4350 - val_accuracy: 0.4823 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "222/222 [==============================] - 7s 32ms/step - loss: 1.3381 - accuracy: 0.4963 - val_loss: 1.4099 - val_accuracy: 0.4823 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "222/222 [==============================] - 7s 32ms/step - loss: 1.2598 - accuracy: 0.5287 - val_loss: 1.4021 - val_accuracy: 0.4960 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "222/222 [==============================] - 7s 33ms/step - loss: 1.2166 - accuracy: 0.5438 - val_loss: 1.3247 - val_accuracy: 0.5181 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "222/222 [==============================] - ETA: 0s - loss: 1.1863 - accuracy: 0.5521\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "222/222 [==============================] - 7s 32ms/step - loss: 1.1863 - accuracy: 0.5521 - val_loss: 1.3605 - val_accuracy: 0.5044 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "222/222 [==============================] - 7s 33ms/step - loss: 1.1307 - accuracy: 0.5744 - val_loss: 1.3159 - val_accuracy: 0.5237 - lr: 5.0000e-04\n",
      "Epoch 7/100\n",
      "222/222 [==============================] - 7s 32ms/step - loss: 1.1177 - accuracy: 0.5810 - val_loss: 1.3264 - val_accuracy: 0.5222 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "222/222 [==============================] - 7s 33ms/step - loss: 1.1098 - accuracy: 0.5812 - val_loss: 1.3130 - val_accuracy: 0.5274 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "222/222 [==============================] - ETA: 0s - loss: 1.1057 - accuracy: 0.5853\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "222/222 [==============================] - 7s 32ms/step - loss: 1.1057 - accuracy: 0.5853 - val_loss: 1.3293 - val_accuracy: 0.5226 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "222/222 [==============================] - 7s 33ms/step - loss: 1.0808 - accuracy: 0.5916 - val_loss: 1.3112 - val_accuracy: 0.5264 - lr: 2.5000e-04\n",
      "Epoch 11/100\n",
      "222/222 [==============================] - 7s 33ms/step - loss: 1.0757 - accuracy: 0.5965 - val_loss: 1.3068 - val_accuracy: 0.5356 - lr: 2.5000e-04\n",
      "Epoch 12/100\n",
      "222/222 [==============================] - 7s 33ms/step - loss: 1.0715 - accuracy: 0.5958 - val_loss: 1.3105 - val_accuracy: 0.5329 - lr: 2.5000e-04\n",
      "Epoch 13/100\n",
      "222/222 [==============================] - ETA: 0s - loss: 1.0692 - accuracy: 0.5981\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "222/222 [==============================] - 7s 32ms/step - loss: 1.0692 - accuracy: 0.5981 - val_loss: 1.3112 - val_accuracy: 0.5320 - lr: 2.5000e-04\n",
      "Epoch 14/100\n",
      "222/222 [==============================] - 7s 33ms/step - loss: 1.0570 - accuracy: 0.6041 - val_loss: 1.3048 - val_accuracy: 0.5353 - lr: 1.2500e-04\n",
      "Epoch 15/100\n",
      "222/222 [==============================] - 7s 33ms/step - loss: 1.0549 - accuracy: 0.6032 - val_loss: 1.3087 - val_accuracy: 0.5359 - lr: 1.2500e-04\n",
      "Epoch 16/100\n",
      "222/222 [==============================] - 7s 32ms/step - loss: 1.0540 - accuracy: 0.6058 - val_loss: 1.3114 - val_accuracy: 0.5326 - lr: 1.2500e-04\n",
      "Epoch 17/100\n",
      "222/222 [==============================] - ETA: 0s - loss: 1.0531 - accuracy: 0.6049\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "222/222 [==============================] - 7s 33ms/step - loss: 1.0531 - accuracy: 0.6049 - val_loss: 1.3129 - val_accuracy: 0.5318 - lr: 1.2500e-04\n",
      "Epoch 18/100\n",
      "222/222 [==============================] - ETA: 0s - loss: 1.0468 - accuracy: 0.6092Restoring model weights from the end of the best epoch: 14.\n",
      "222/222 [==============================] - 7s 33ms/step - loss: 1.0468 - accuracy: 0.6092 - val_loss: 1.3071 - val_accuracy: 0.5363 - lr: 6.2500e-05\n",
      "Epoch 18: early stopping\n"
     ]
    }
   ],
   "source": [
    "# VGG 19\n",
    "# 1. Create a base model with tf.keras.applciations\n",
    "base_model1 = tf.keras.applications.ResNet50V2(include_top=False, input_shape=(48,48,3)) # include_top -> last layer (will be different for different datasets)\n",
    "# base_model2 = tf.keras.applications.VGG19(include_top=False, input_shape=(48,48,3))\n",
    "# 2. Freeze the base model, underlying pre-trained weights arent updated during training\n",
    "base_model1.trainable=False\n",
    "# base_model2.trainable=False\n",
    "\n",
    "# 3. Create inputs into our model\n",
    "inputs = tf.keras.layers.Input(shape=(48,48,3),\n",
    "                               name=\"input_layer\")\n",
    "\n",
    "# 4. (Optional) -> if using resnet -> need to normalize inputs -> not needed for EfficientNet\n",
    "x = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)(inputs)\n",
    "\n",
    "# 5. Pass the inputs to base_model\n",
    "x1 = base_model1(inputs)\n",
    "\n",
    "# print(\"shape after passing inputs through base_model: \"+str(x.shape))\n",
    "\n",
    "# 6. Average pool the outputs of the base_model (aggregate all most of information, reduce number of computations)\n",
    "x1 = tf.keras.layers.GlobalAveragePooling2D(name=\"average_global_pooling_layer\")(x1)\n",
    "# x2 = tf.keras.layers.GlobalAveragePooling2D(name=\"average_global_pooling_layer\")(x2)\n",
    "\n",
    "# print(\"Shape after GlobalAveragePooling2D: \"+str(x.shape))\n",
    "\n",
    "# 7. Create the output activation layer\n",
    "outputs1 = tf.keras.layers.Dense(8,activation=tf.keras.activations.softmax,name=\"output_layers\")(x1)\n",
    "# outputs2 = tf.keras.layers.Dense(8,activation=tf.keras.activations.softmax,name=\"output_layers\")(x2)\n",
    "\n",
    "# 8. Combine input with the outputs into a model\n",
    "model_resnet = tf.keras.Model(inputs,outputs1)\n",
    "# model_vgg19 = tf.keras.Model(inputs,outputs2)\n",
    "\n",
    "# 9. Compile the model\n",
    "model_resnet.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# 10. Fit the model\n",
    "history_resnet = model_resnet.fit(train_data,\n",
    "                        epochs=100,\n",
    "                        steps_per_epoch=len(train_data),\n",
    "                        validation_data=test_data,\n",
    "                        validation_steps=len(test_data),\n",
    "                        callbacks=[lr_scheduler,early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28386 images belonging to 8 classes.\n",
      "Found 7099 images belonging to 8 classes.\n",
      "Epoch 1/100\n",
      "222/222 [==============================] - 20s 64ms/step - loss: 1.6172 - accuracy: 0.3550 - val_loss: 1.6127 - val_accuracy: 0.3658 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "222/222 [==============================] - 13s 57ms/step - loss: 1.6127 - accuracy: 0.3527 - val_loss: 1.6188 - val_accuracy: 0.3658 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "222/222 [==============================] - 13s 57ms/step - loss: 1.6108 - accuracy: 0.3575 - val_loss: 1.6234 - val_accuracy: 0.3658 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "222/222 [==============================] - 13s 57ms/step - loss: 1.6123 - accuracy: 0.3534 - val_loss: 1.6141 - val_accuracy: 0.3658 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "221/222 [============================>.] - ETA: 0s - loss: 1.6111 - accuracy: 0.3545\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "222/222 [==============================] - 13s 58ms/step - loss: 1.6110 - accuracy: 0.3545 - val_loss: 1.6263 - val_accuracy: 0.3658 - lr: 0.0010\n",
      "Epoch 5: early stopping\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_dir=\"fer2013plus/fer2013/train/\"\n",
    "test_dir=\"fer2013plus/fer2013/test/\"\n",
    "\n",
    "\n",
    "train_data = train_datagen.flow_from_directory(train_dir,\n",
    "                                               batch_size=128,\n",
    "                                               target_size=(48,48),\n",
    "                                               class_mode=\"categorical\",\n",
    "                                               seed=42)\n",
    "test_data = test_datagen.flow_from_directory(test_dir,\n",
    "                                             batch_size=128,\n",
    "                                             target_size=(48,48),\n",
    "                                             class_mode=\"categorical\",\n",
    "                                             seed=42)\n",
    "\n",
    "\n",
    "# 1. Create a base model with tf.keras.applciations\n",
    "base_model1 = tf.keras.applications.EfficientNetB4(include_top=False, input_shape=(48,48,3)) # include_top -> last layer (will be different for different datasets)\n",
    "# base_model2 = tf.keras.applications.VGG19(include_top=False, input_shape=(48,48,3))\n",
    "# 2. Freeze the base model, underlying pre-trained weights arent updated during training\n",
    "base_model1.trainable=False\n",
    "# base_model2.trainable=False\n",
    "\n",
    "# 3. Create inputs into our model\n",
    "inputs = tf.keras.layers.Input(shape=(48,48,3),\n",
    "                               name=\"input_layer\")\n",
    "\n",
    "# 4. (Optional) -> if using resnet -> need to normalize inputs -> not needed for EfficientNet\n",
    "# x = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)(inputs)\n",
    "\n",
    "# 5. Pass the inputs to base_model\n",
    "x1 = base_model1(inputs)\n",
    "\n",
    "# print(\"shape after passing inputs through base_model: \"+str(x.shape))\n",
    "\n",
    "# 6. Average pool the outputs of the base_model (aggregate all most of information, reduce number of computations)\n",
    "x1 = tf.keras.layers.GlobalAveragePooling2D(name=\"average_global_pooling_layer\")(x1)\n",
    "# x2 = tf.keras.layers.GlobalAveragePooling2D(name=\"average_global_pooling_layer\")(x2)\n",
    "\n",
    "# print(\"Shape after GlobalAveragePooling2D: \"+str(x.shape))\n",
    "\n",
    "# 7. Create the output activation layer\n",
    "outputs1 = tf.keras.layers.Dense(8,activation=tf.keras.activations.softmax,name=\"output_layers\")(x1)\n",
    "# outputs2 = tf.keras.layers.Dense(8,activation=tf.keras.activations.softmax,name=\"output_layers\")(x2)\n",
    "\n",
    "# 8. Combine input with the outputs into a model\n",
    "model_eff_4 = tf.keras.Model(inputs,outputs1)\n",
    "# model_vgg19 = tf.keras.Model(inputs,outputs2)\n",
    "\n",
    "# 9. Compile the model\n",
    "model_eff_4.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# 10. Fit the model\n",
    "history_eff_4 = model_eff_4.fit(train_data,\n",
    "                        epochs=100,\n",
    "                        steps_per_epoch=len(train_data),\n",
    "                        validation_data=test_data,\n",
    "                        validation_steps=len(test_data),\n",
    "                        callbacks=[lr_scheduler,early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'efficientnetb4'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_eff_4.layers[1].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.6172040700912476,\n",
       "  1.6127369403839111,\n",
       "  1.6108163595199585,\n",
       "  1.612305760383606,\n",
       "  1.6109644174575806],\n",
       " 'accuracy': [0.35499894618988037,\n",
       "  0.35267385840415955,\n",
       "  0.3574649393558502,\n",
       "  0.35337841510772705,\n",
       "  0.35454097390174866],\n",
       " 'val_loss': [1.6126809120178223,\n",
       "  1.6187567710876465,\n",
       "  1.6233959197998047,\n",
       "  1.6141363382339478,\n",
       "  1.6263082027435303],\n",
       " 'val_accuracy': [0.36582615971565247,\n",
       "  0.36582615971565247,\n",
       "  0.36582615971565247,\n",
       "  0.36582615971565247,\n",
       "  0.36582615971565247],\n",
       " 'lr': [0.001, 0.001, 0.001, 0.001, 0.001]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_eff_4.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names=[\"vgg16\",\"vgg19\",\"effnetb4\",\"resnet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def save_csv(hist=[],model_names=[]):\n",
    "    for i in range(len(hist)):\n",
    "        pd.DataFrame(hist[i].history).to_csv(f'history/hist{model_names[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_csv([history_vgg16,history_vgg19,history_eff_4,history_resnet],model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-14 19:04:13.851457: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-14 19:04:15.363693: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-14 19:04:15.381621: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-14 19:04:15.381759: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-14 19:04:15.382493: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-14 19:04:15.383350: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-14 19:04:15.383460: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-14 19:04:15.383534: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-14 19:04:15.427446: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-14 19:04:15.427570: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-14 19:04:15.427648: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-14 19:04:15.427726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2287 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.callbacks.History object at 0x7f18303d4370>\n"
     ]
    }
   ],
   "source": [
    "import pickle as pk\n",
    "with open('file.pkl', 'rb') as file:\n",
    "      \n",
    "    # Call load method to deserialze\n",
    "    history_dcnn = pk.load(file)\n",
    "  \n",
    "    print(history_dcnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.5211914777755737,\n",
       "  1.0289682149887085,\n",
       "  0.8539248704910278,\n",
       "  0.7725116014480591,\n",
       "  0.7083613872528076,\n",
       "  0.6120865345001221,\n",
       "  0.5656148195266724,\n",
       "  0.5307382345199585,\n",
       "  0.49736183881759644,\n",
       "  0.42269113659858704,\n",
       "  0.3852015435695648,\n",
       "  0.3599364757537842,\n",
       "  0.33289071917533875,\n",
       "  0.2808707058429718,\n",
       "  0.24455679953098297],\n",
       " 'accuracy': [0.47270166873931885,\n",
       "  0.6382088661193848,\n",
       "  0.6935540437698364,\n",
       "  0.7255195379257202,\n",
       "  0.7496037483215332,\n",
       "  0.7845191955566406,\n",
       "  0.8016907572746277,\n",
       "  0.8116413950920105,\n",
       "  0.8217682242393494,\n",
       "  0.8494628667831421,\n",
       "  0.8630679845809937,\n",
       "  0.8724462985992432,\n",
       "  0.8800634145736694,\n",
       "  0.8978953957557678,\n",
       "  0.9138781428337097],\n",
       " 'val_loss': [1.3328057527542114,\n",
       "  1.0972977876663208,\n",
       "  0.852575957775116,\n",
       "  0.8722752928733826,\n",
       "  1.351462483406067,\n",
       "  0.7148497700691223,\n",
       "  0.6702989935874939,\n",
       "  0.6665971279144287,\n",
       "  0.7109628915786743,\n",
       "  0.6508536338806152,\n",
       "  0.6024495363235474,\n",
       "  0.6347486972808838,\n",
       "  0.6615105867385864,\n",
       "  0.6421643495559692,\n",
       "  0.6558812260627747],\n",
       " 'val_accuracy': [0.5301374793052673,\n",
       "  0.6133239269256592,\n",
       "  0.7025026679039001,\n",
       "  0.691399335861206,\n",
       "  0.5505815744400024,\n",
       "  0.7485019564628601,\n",
       "  0.7629538178443909,\n",
       "  0.7648925185203552,\n",
       "  0.7537891864776611,\n",
       "  0.7744095921516418,\n",
       "  0.7937962412834167,\n",
       "  0.7839266657829285,\n",
       "  0.7786394357681274,\n",
       "  0.7987310290336609,\n",
       "  0.7974973320960999],\n",
       " 'lr': [0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.005,\n",
       "  0.005,\n",
       "  0.005,\n",
       "  0.005,\n",
       "  0.0025,\n",
       "  0.0025,\n",
       "  0.0025,\n",
       "  0.0025,\n",
       "  0.00125,\n",
       "  0.00125]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dcnn.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "hist_vgg_16=pd.read_csv(\"history/histvgg16\")\n",
    "hist_vgg_16=hist_vgg_16.drop(\"Unnamed: 0\",axis=1).to_dict()\n",
    "\n",
    "hist_vgg_19=pd.read_csv(\"history/histvgg19\")\n",
    "hist_vgg_19=hist_vgg_19.drop(\"Unnamed: 0\",axis=1).to_dict()\n",
    "\n",
    "hist_resnet=pd.read_csv(\"history/histresnet\")\n",
    "hist_resnet=hist_resnet.drop(\"Unnamed: 0\",axis=1).to_dict()\n",
    "\n",
    "hist_effnetb4=pd.read_csv(\"history/histeffnetb4\")\n",
    "hist_effnetb4=hist_effnetb4.drop(\"Unnamed: 0\",axis=1).to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist=[hist_resnet,history_vgg_16,hist_vgg_19,hist_effnetb4,history_dcnn.history]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names=[\"resnet\",\"vgg16\",'vgg19',\"efficientNetb4\",\"Proposed DCNN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m         plt\u001b[39m.\u001b[39msavefig(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mplot_model/\u001b[39m\u001b[39m{\u001b[39;00mmetrics_title[j]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[0;32m---> 26\u001b[0m plot_hi(hist, model_names)\n",
      "Cell \u001b[0;32mIn[35], line 20\u001b[0m, in \u001b[0;36mplot_hi\u001b[0;34m(hist, model)\u001b[0m\n\u001b[1;32m     18\u001b[0m plt\u001b[39m.\u001b[39msubplot(\u001b[39m2\u001b[39m,\u001b[39m2\u001b[39m,j\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(hist)):\n\u001b[0;32m---> 20\u001b[0m     plt\u001b[39m.\u001b[39;49mplot(metrics[j][i],c\u001b[39m=\u001b[39;49mc[i],label\u001b[39m=\u001b[39;49mmodel[i])\n\u001b[1;32m     21\u001b[0m plt\u001b[39m.\u001b[39mtitle(metrics_title[j])\n\u001b[1;32m     22\u001b[0m plt\u001b[39m.\u001b[39mlegend()\n",
      "File \u001b[0;32m~/miniconda3/envs/TF/lib/python3.8/site-packages/matplotlib/pyplot.py:2740\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2738\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39mplot)\n\u001b[1;32m   2739\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot\u001b[39m(\u001b[39m*\u001b[39margs, scalex\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, scaley\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m-> 2740\u001b[0m     \u001b[39mreturn\u001b[39;00m gca()\u001b[39m.\u001b[39;49mplot(\n\u001b[1;32m   2741\u001b[0m         \u001b[39m*\u001b[39;49margs, scalex\u001b[39m=\u001b[39;49mscalex, scaley\u001b[39m=\u001b[39;49mscaley,\n\u001b[1;32m   2742\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m({\u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\"\u001b[39;49m: data} \u001b[39mif\u001b[39;49;00m data \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m {}), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/TF/lib/python3.8/site-packages/matplotlib/axes/_axes.py:1664\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1662\u001b[0m lines \u001b[39m=\u001b[39m [\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_lines(\u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39mdata, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)]\n\u001b[1;32m   1663\u001b[0m \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m lines:\n\u001b[0;32m-> 1664\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_line(line)\n\u001b[1;32m   1665\u001b[0m \u001b[39mif\u001b[39;00m scalex:\n\u001b[1;32m   1666\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_request_autoscale_view(\u001b[39m\"\u001b[39m\u001b[39mx\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/TF/lib/python3.8/site-packages/matplotlib/axes/_base.py:2340\u001b[0m, in \u001b[0;36m_AxesBase.add_line\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m   2337\u001b[0m \u001b[39mif\u001b[39;00m line\u001b[39m.\u001b[39mget_clip_path() \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2338\u001b[0m     line\u001b[39m.\u001b[39mset_clip_path(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpatch)\n\u001b[0;32m-> 2340\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_line_limits(line)\n\u001b[1;32m   2341\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m line\u001b[39m.\u001b[39mget_label():\n\u001b[1;32m   2342\u001b[0m     line\u001b[39m.\u001b[39mset_label(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m_child\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_children)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/TF/lib/python3.8/site-packages/matplotlib/axes/_base.py:2363\u001b[0m, in \u001b[0;36m_AxesBase._update_line_limits\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_line_limits\u001b[39m(\u001b[39mself\u001b[39m, line):\n\u001b[1;32m   2360\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2361\u001b[0m \u001b[39m    Figures out the data limit of the given line, updating self.dataLim.\u001b[39;00m\n\u001b[1;32m   2362\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2363\u001b[0m     path \u001b[39m=\u001b[39m line\u001b[39m.\u001b[39;49mget_path()\n\u001b[1;32m   2364\u001b[0m     \u001b[39mif\u001b[39;00m path\u001b[39m.\u001b[39mvertices\u001b[39m.\u001b[39msize \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   2365\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/TF/lib/python3.8/site-packages/matplotlib/lines.py:1031\u001b[0m, in \u001b[0;36mLine2D.get_path\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1029\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Return the `~matplotlib.path.Path` associated with this line.\"\"\"\u001b[39;00m\n\u001b[1;32m   1030\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_invalidy \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_invalidx:\n\u001b[0;32m-> 1031\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrecache()\n\u001b[1;32m   1032\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_path\n",
      "File \u001b[0;32m~/miniconda3/envs/TF/lib/python3.8/site-packages/matplotlib/lines.py:664\u001b[0m, in \u001b[0;36mLine2D.recache\u001b[0;34m(self, always)\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[39mif\u001b[39;00m always \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_invalidy:\n\u001b[1;32m    663\u001b[0m     yconv \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvert_yunits(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_yorig)\n\u001b[0;32m--> 664\u001b[0m     y \u001b[39m=\u001b[39m _to_unmasked_float_array(yconv)\u001b[39m.\u001b[39mravel()\n\u001b[1;32m    665\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    666\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_y\n",
      "File \u001b[0;32m~/miniconda3/envs/TF/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1369\u001b[0m, in \u001b[0;36m_to_unmasked_float_array\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mma\u001b[39m.\u001b[39masarray(x, \u001b[39mfloat\u001b[39m)\u001b[39m.\u001b[39mfilled(np\u001b[39m.\u001b[39mnan)\n\u001b[1;32m   1368\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1369\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49masarray(x, \u001b[39mfloat\u001b[39;49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'dict'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x1600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_hi(hist=[],model=[]):\n",
    "    val_acc=[]\n",
    "    val_loss=[]\n",
    "    loss=[]\n",
    "    accuracy=[]\n",
    "    metrics=[val_acc,accuracy,val_loss,loss]\n",
    "    metrics_title=[\"val_acc\",\"accuracy\",\"val_loss\",\"loss\"]\n",
    "    for history in hist:\n",
    "        accuracy.append(history[\"accuracy\"])\n",
    "        val_acc.append(history[\"val_accuracy\"])\n",
    "        loss.append(history[\"loss\"])\n",
    "        val_loss.append(history[\"val_loss\"])\n",
    "    \n",
    "    plt.figure(figsize=(16,16))\n",
    "    c=['g','r','b','orange',\"black\"]\n",
    "    for j in range(len(metrics)):\n",
    "        plt.subplot(2,2,j+1)\n",
    "        for i in range(len(hist)):\n",
    "            plt.plot(metrics[j][i],c=c[i],label=model[i])\n",
    "        plt.title(metrics_title[j])\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"plot_model/{metrics_title[j]}\")\n",
    "\n",
    "    plt.show()\n",
    "plot_hi(hist, model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/56 [..............................] - ETA: 2s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 3s 45ms/step\n",
      "56/56 [==============================] - 3s 45ms/step\n",
      "56/56 [==============================] - 1s 26ms/step\n",
      "56/56 [==============================] - 4s 63ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_vgg16 = model_vgg19.predict(test_data)\n",
    "y_pred_vgg19 = model_vgg19.predict(test_data)\n",
    "y_pred_resnet = model_resnet.predict(test_data)\n",
    "y_pred_effnetb4 = model_eff_4.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_vgg16 = tf.argmax(y_pred_vgg16,axis=1)\n",
    "y_pred_vgg19 = tf.argmax(y_pred_vgg19,axis=1)\n",
    "y_pred_resnet = tf.argmax(y_pred_resnet,axis=1)\n",
    "y_pred_effnetb4 = tf.argmax(y_pred_effnetb4,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 28.257501056486827, 'precision': 0.2290343208438146, 'recall': 0.28257501056486833, 'f1': 0.24719325042904855}\n",
      "{'accuracy': 29.48302577827863, 'precision': 0.24518252371213622, 'recall': 0.2948302577827863, 'f1': 0.26001958053808644}\n",
      "{'accuracy': 27.00380335258487, 'precision': 0.24050591370291752, 'recall': 0.2700380335258487, 'f1': 0.2520829492907257}\n",
      "{'accuracy': 36.58261727003803, 'precision': 0.1338287886326085, 'recall': 0.3658261727003803, 'f1': 0.19596752691891248}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from helper_functions import calculate_results\n",
    "print(\"vgg16\",calculate_results(test_data.labels,y_pred_vgg16.numpy()))\n",
    "print(calculate_results(test_data.labels,y_pred_vgg19.numpy()))\n",
    "print(calculate_results(test_data.labels,y_pred_resnet.numpy()))\n",
    "print(calculate_results(test_data.labels,y_pred_effnetb4.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"DCNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 48, 48, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 48, 48, 64)        640       \n",
      "                                                                 \n",
      " batchnorm_1 (BatchNormaliza  (None, 48, 48, 64)       256       \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 48, 48, 64)        36928     \n",
      "                                                                 \n",
      " batchnorm_2 (BatchNormaliza  (None, 48, 48, 64)       256       \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " maxpool2d_1 (MaxPooling2D)  (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 24, 24, 128)       73856     \n",
      "                                                                 \n",
      " batchnorm_3 (BatchNormaliza  (None, 24, 24, 128)      512       \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 24, 24, 128)       147584    \n",
      "                                                                 \n",
      " batchnorm_4 (BatchNormaliza  (None, 24, 24, 128)      512       \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " maxpool2d_2 (MaxPooling2D)  (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 12, 12, 256)       295168    \n",
      "                                                                 \n",
      " batchnorm_5 (BatchNormaliza  (None, 12, 12, 256)      1024      \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " batchnorm_6 (BatchNormaliza  (None, 12, 12, 256)      1024      \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " maxpool2d_3 (MaxPooling2D)  (None, 6, 6, 256)         0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 6, 6, 256)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9216)              0         \n",
      "                                                                 \n",
      " dense1 (Dense)              (None, 128)               1179776   \n",
      "                                                                 \n",
      " batchnorm_7 (BatchNormaliza  (None, 128)              512       \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " out_layer (Dense)           (None, 8)                 1032      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,329,160\n",
      "Trainable params: 1,181,064\n",
      "Non-trainable params: 1,148,096\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_dcnn = tf.keras.models.load_model(\"high\")\n",
    "model_dcnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Graph execution error:\n\nDetected at node 'DCNN/conv2d_1/Conv2D' defined at (most recent call last):\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_149414/1780590433.py\", line 1, in <module>\n      calculate_results(test_data.labels, tf.argmax(model_dcnn.predict(test_data),axis=1).numpy())\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/keras/engine/training.py\", line 2033, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/keras/engine/training.py\", line 1845, in predict_function\n      return step_function(self, iterator)\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/keras/engine/training.py\", line 1834, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/keras/engine/training.py\", line 1823, in run_step\n      outputs = model.predict_step(data)\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/keras/engine/training.py\", line 1791, in predict_step\n      return self(x, training=False)\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/keras/engine/training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/keras/engine/functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/keras/engine/functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py\", line 250, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py\", line 225, in convolution_op\n      return tf.nn.convolution(\nNode: 'DCNN/conv2d_1/Conv2D'\nNo algorithm worked!  Error messages:\n\t [[{{node DCNN/conv2d_1/Conv2D}}]] [Op:__inference_predict_function_189049]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m calculate_results(test_data\u001b[39m.\u001b[39mlabels, tf\u001b[39m.\u001b[39margmax(model_dcnn\u001b[39m.\u001b[39;49mpredict(test_data),axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m~/miniconda3/envs/TF/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/TF/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Graph execution error:\n\nDetected at node 'DCNN/conv2d_1/Conv2D' defined at (most recent call last):\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_149414/1780590433.py\", line 1, in <module>\n      calculate_results(test_data.labels, tf.argmax(model_dcnn.predict(test_data),axis=1).numpy())\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/keras/engine/training.py\", line 2033, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/keras/engine/training.py\", line 1845, in predict_function\n      return step_function(self, iterator)\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/keras/engine/training.py\", line 1834, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/keras/engine/training.py\", line 1823, in run_step\n      outputs = model.predict_step(data)\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/keras/engine/training.py\", line 1791, in predict_step\n      return self(x, training=False)\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/keras/engine/training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/keras/engine/functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/keras/engine/functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py\", line 250, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/home/ujjwal/miniconda3/envs/TF/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py\", line 225, in convolution_op\n      return tf.nn.convolution(\nNode: 'DCNN/conv2d_1/Conv2D'\nNo algorithm worked!  Error messages:\n\t [[{{node DCNN/conv2d_1/Conv2D}}]] [Op:__inference_predict_function_189049]"
     ]
    }
   ],
   "source": [
    "calculate_results(test_data.labels, tf.argmax(model_dcnn.predict(test_data),axis=1).numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
